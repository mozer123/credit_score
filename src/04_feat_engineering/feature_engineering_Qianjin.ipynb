{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEK 4: Feature Engineering and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datasets\n",
    "outflow = pd.read_parquet(\"ucsd-outflows.pqt\")\n",
    "inflow = pd.read_parquet(\"ucsd-inflows.pqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with 'memo' uncleaned\n",
    "outflow_uncleaned = outflow[outflow['memo'] != outflow['category']]\n",
    "\n",
    "# Lower case all values in memo\n",
    "outflow_uncleaned.loc[:, 'memo'] = outflow_uncleaned['memo'].apply(lambda x: x.lower())\n",
    "\n",
    "# Remove special characters and numbers\n",
    "outflow_uncleaned.loc[:, 'memo'] = outflow_uncleaned['memo'].apply(lambda x: re.sub(r'[^a-z\\s]', ' ', x))\n",
    "\n",
    "# Remove placeholders\n",
    "outflow_uncleaned.loc[:, 'memo'] = outflow_uncleaned['memo'].apply(lambda x: re.sub(r'xxx+', ' ', x))\n",
    "\n",
    "# Remove extra spaces\n",
    "outflow_uncleaned.loc[:, 'memo'] = outflow_uncleaned['memo'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "\n",
    "# Observe the first 5000 rows of the cleaned 'memo' column \n",
    "print(outflow_uncleaned.iloc[:5000, :]['memo'].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format the outflow dataset\n",
    "outflow_cleaned = outflow[outflow['memo'] == outflow['category']]\n",
    "outflow_memo = pd.concat([outflow_uncleaned, outflow_cleaned]).sort_index()\n",
    "outflow_memo['memo_default'] = outflow['memo']\n",
    "outflow_memo = outflow_memo[['prism_consumer_id', 'prism_account_id', 'memo_default', 'memo','amount', 'posted_date', 'category']]\n",
    "outflow_memo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outflow_data = outflow_memo.copy()\n",
    "\n",
    "# Conduct train-test split on dataset based on customer ids\n",
    "customer_id = outflow_data['prism_consumer_id'].unique()\n",
    "\n",
    "train_id, test_id = train_test_split(customer_id, test_size= 0.25, random_state = 42)\n",
    "\n",
    "train_data = outflow_data[outflow_data['prism_consumer_id'].isin(train_id)]\n",
    "test_data = outflow_data[outflow_data['prism_consumer_id'].isin(test_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate TF-IDF features from the cleaned memo column\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features = 1000)\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(train_data['memo']).toarray()\n",
    "\n",
    "# Convert TF-IDF features to DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_features, columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Convert 'posted_date' to datetime\n",
    "date_series = pd.to_datetime(outflow_data['posted_date'])\n",
    "\n",
    "# Create new date-based features\n",
    "outflow_data['day_of_week'] = date_series.dt.dayofweek\n",
    "outflow_data['day_of_month'] = date_series.dt.day\n",
    "\n",
    "# Create an indicator if the amount is a whole dollar\n",
    "outflow_data['whole_dollar'] = (outflow_data['amount'] % 1 == 0).astype(int)\n",
    "\n",
    "# Combine TF-IDF features with date/amount-based features\n",
    "features = pd.concat([tfidf_df, outflow_data[['day_of_week', 'day_of_month', 'whole_dollar', 'amount']]\n",
    "                      .reset_index().drop(columns=['index'])], axis=1)\n",
    "labels = outflow_data['category']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Logistic Regression F1-Score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "# Train Random Forest model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Random Forest F1-Score:\", f1_score(y_test, y_pred_rf, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
