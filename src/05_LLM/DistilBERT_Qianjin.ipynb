{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datasets\n",
    "outflow = pd.read_parquet(\"ucsd-outflows.pqt\")\n",
    "inflow = pd.read_parquet(\"ucsd-inflows.pqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset for testing\n",
    "inflow_subset = inflow.sample(n=12500, random_state=42)\n",
    "outflow_subset = outflow.sample(n=12500, random_state=42)\n",
    "inflow = inflow_subset\n",
    "outflow = outflow_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with 'memo' uncleaned\n",
    "outflow_cleaned = outflow[outflow['memo'] != outflow['category']]\n",
    "\n",
    "# Lower case all values in memo\n",
    "outflow_cleaned.loc[:, 'memo'] = outflow_cleaned['memo'].apply(lambda x: x.lower())\n",
    "\n",
    "# Remove special characters and numbers\n",
    "outflow_cleaned.loc[:, 'memo'] = outflow_cleaned['memo'].apply(lambda x: re.sub(r'[^a-z\\s]', ' ', x))\n",
    "\n",
    "# Remove placeholders\n",
    "outflow_cleaned.loc[:, 'memo'] = outflow_cleaned['memo'].apply(lambda x: re.sub(r'xxx+', ' ', x))\n",
    "\n",
    "# Remove extra spaces\n",
    "outflow_cleaned.loc[:, 'memo'] = outflow_cleaned['memo'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "\n",
    "outflow_data = outflow_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from category names to integer labels\n",
    "category_mapping = {category: idx for idx, category in enumerate(outflow_data['category'].unique())}\n",
    "\n",
    "# Apply this mapping to create a new integer labels column\n",
    "outflow_data['labels'] = outflow_data['category'].map(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba6948eb06a4ff986380cc493a2e377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/6292 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33d67bfdd814552a29033a51f06b7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/6292 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get unique customer IDs from the DataFrame first\n",
    "unique_customer_ids = outflow_data['prism_consumer_id'].unique()\n",
    "\n",
    "# Split customer IDs into training and test sets\n",
    "train_ids, test_ids = train_test_split(unique_customer_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the DataFrame to a Hugging Face Dataset after splitting\n",
    "dataset = Dataset.from_pandas(outflow_data)\n",
    "\n",
    "# Filter the dataset by customer ID\n",
    "train_data = dataset.filter(lambda x: x['prism_consumer_id'] in train_ids)\n",
    "test_data = dataset.filter(lambda x: x['prism_consumer_id'] in test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4d6dea93f74f508bd44de8685b6f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5027 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd26dfa7c0b7401d85a454bbe223af69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1265 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize the data and retain labels\n",
    "def tokenize_data(batch):\n",
    "    tokenized_batch = tokenizer(batch['memo'], padding='max_length', truncation=True)\n",
    "    tokenized_batch[\"labels\"] = batch[\"labels\"]\n",
    "    return tokenized_batch\n",
    "\n",
    "# Tokenize dataset\n",
    "train_data = train_data.map(tokenize_data, batched=True)\n",
    "test_data = test_data.map(tokenize_data, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prism_consumer_id', 'prism_account_id', 'text', 'amount', 'posted_date', 'category', 'labels', '__index_level_0__', 'input_ids', 'attention_mask']\n",
      "['prism_consumer_id', 'prism_account_id', 'text', 'amount', 'posted_date', 'category', 'labels', '__index_level_0__', 'input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.rename_column(\"memo\", \"text\")\n",
    "test_data = test_data.rename_column(\"memo\", \"text\")\n",
    "\n",
    "print(train_data.column_names)\n",
    "print(test_data.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define number of labels (categories)\n",
    "num_labels = len(outflow_data['category'].unique())\n",
    "\n",
    "# Load DistilBERT with a classification layer\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianjin/anaconda3/envs/creditrisk/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e48d4187aa4a77ba45b654d58bfbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/945 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5077, 'grad_norm': 3.6194894313812256, 'learning_rate': 2.3544973544973546e-05, 'epoch': 1.59}\n",
      "{'train_runtime': 818.6952, 'train_samples_per_second': 18.421, 'train_steps_per_second': 1.154, 'train_loss': 0.34212417198867395, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=945, training_loss=0.34212417198867395, metrics={'train_runtime': 818.6952, 'train_samples_per_second': 18.421, 'train_steps_per_second': 1.154, 'total_flos': 1997990227233792.0, 'train_loss': 0.34212417198867395, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"no\",     \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=16,  \n",
    "    num_train_epochs=3,            \n",
    "    weight_decay=0.01,            \n",
    ")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,             \n",
    "    train_dataset=train_data,       \n",
    "    eval_dataset=test_data              \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708e8acf925f469ea950e851867896ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4670441448688507,\n",
       " 'eval_runtime': 24.3881,\n",
       " 'eval_samples_per_second': 51.869,\n",
       " 'eval_steps_per_second': 3.28,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51d0c04460742f6aa2badbee3a7dfe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "# Update the Trainer with custom compute_metrics\n",
    "trainer.compute_metrics = compute_metrics\n",
    "\n",
    "# Re-run evaluation\n",
    "eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics to a text file\n",
    "output_file = \"evaluation_metrics.txt\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    file.write(\"Evaluation Metrics on Test Set\\n\")\n",
    "    file.write(\"=============================\\n\")\n",
    "    for key, value in eval_results.items():\n",
    "        file.write(f\"{key}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metrics on Test Set\n",
    "=============================\n",
    "eval_loss: 0.4670441448688507  \n",
    "eval_accuracy: 0.8956521739130435  \n",
    "eval_f1: 0.8930265530973801  \n",
    "eval_runtime: 23.137  \n",
    "eval_samples_per_second: 54.674  \n",
    "eval_steps_per_second: 3.458  \n",
    "epoch: 3.0  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse category_mapping to create index_to_category\n",
    "index_to_category = {v: k for k, v in category_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'purchase authorized on fordham deli bronx ny s card'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outflow_cleaned.iloc[0]['memo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: FOOD_AND_BEVERAGES\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a new transaction memo\n",
    "new_memo = outflow_cleaned.iloc[0]['memo']\n",
    "\n",
    "\n",
    "model.to('mps')\n",
    "\n",
    "# Tokenize and move inputs to MPS\n",
    "inputs = tokenizer(new_memo, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "inputs = {key: value.to('mps') for key, value in inputs.items()}\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predictions = outputs.logits.argmax(-1)\n",
    "    predicted_category = predictions.item()\n",
    "\n",
    "print(\"Predicted Category:\", index_to_category[predicted_category])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FOOD_AND_BEVERAGES': 0, 'GROCERIES': 1, 'GENERAL_MERCHANDISE': 2, 'EDUCATION': 3, 'TRAVEL': 4, 'OVERDRAFT': 5, 'PETS': 6, 'RENT': 7, 'MORTGAGE': 8}\n"
     ]
    }
   ],
   "source": [
    "print(category_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creditrisk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
